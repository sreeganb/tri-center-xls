{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79e6bf7d",
   "metadata": {},
   "source": [
    "# Surrogate modeling or functional approximation for the forward model \n",
    "    - Feed forward neural network, also known as a multilayer perceptron (MLP)\n",
    "## Develop a neural network model that will act as a lookup table and work with IMP\n",
    "* Generate ground truth dataset to train the NN on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e60ce8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import h5py\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from scipy.optimize import minimize_scalar\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.ndimage import gaussian_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40490c03",
   "metadata": {},
   "source": [
    "### MCMC code to generate ground truth data points\n",
    "* Points $\\vec{p_i}$ and $\\vec{p_j}$ picked at random\n",
    "* Spheres of radius $\\sigma_i$ and $\\sigma_j$ around the two points\n",
    "* Volumes of the spheres as $v_i = \\frac{4}{3}\\pi \\left(\\sigma_i\\right)^3$ and $v_j = \\frac{4}{3}\\pi \\left(\\sigma_j\\right)^3$\n",
    "* Check distance $d_{ij} = |\\vec{p_i} -\\vec{p_j}|$\n",
    "    - if $d_{ij} < \\sigma_i + \\sigma_j$\n",
    "        - $xlvol = \\frac{4}{3}\\pi \\left(\\frac{L}{2}\\right)^3$\n",
    "        - $vol_i = min(v_i, xlvol)$\n",
    "        - $vol_j = min(v_j, xlvol)$\n",
    "\n",
    "## Analytical model is not what we shall implement, but a no brainer MCMC code, that will simply pick random points and compute the distances between them, if $d_{ij} < L$ then, store it as success, run the same for some million times, get a converged probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "96671dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 10/100 configurations...\n",
      "Generated 20/100 configurations...\n",
      "Generated 30/100 configurations...\n",
      "Generated 40/100 configurations...\n",
      "Generated 50/100 configurations...\n",
      "Generated 60/100 configurations...\n",
      "Generated 70/100 configurations...\n",
      "Generated 80/100 configurations...\n",
      "Generated 90/100 configurations...\n",
      "Generated 100/100 configurations...\n",
      "Completed! Generated 100 configurations.\n",
      "Saved training data to surrogate_model_data.h5\n",
      "Saved scaler to data_scaler.pkl\n",
      "Training set: 80 samples\n",
      "Validation set: 20 samples\n",
      "Visualized 10/20 configurations...\n",
      "Visualized 20/20 configurations...\n",
      "Saved visualization to output_figures/configurations_visualization.pdf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import h5py\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "class CrosslinkProbabilityEstimator:\n",
    "    '''\n",
    "    Monte Carlo estimator for crosslink probability between two points.\n",
    "    Generates training data, computes probabilities, and visualizes configurations.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    L : float\n",
    "        Crosslinker length threshold (default: 21.0 Angstroms)\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, L=21.0):\n",
    "        self.L = L\n",
    "        self.configurations = []\n",
    "        self.results = []\n",
    "        \n",
    "    def _pick_points(self, p1, p2, sigma1, sigma2):\n",
    "        '''\n",
    "        Sample one point from each uncertainty sphere and check if crosslink is possible.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        p1 : np.ndarray\n",
    "            Center position of first point (shape: (3,))\n",
    "        p2 : np.ndarray\n",
    "            Center position of second point (shape: (3,))\n",
    "        sigma1 : float\n",
    "            Positional uncertainty (radius) for first point\n",
    "        sigma2 : float\n",
    "            Positional uncertainty (radius) for second point\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        bool\n",
    "            True if distance between sampled points < L, False otherwise\n",
    "        '''\n",
    "        q1 = p1 + np.random.normal(0, sigma1, size=p1.shape)\n",
    "        q2 = p2 + np.random.normal(0, sigma2, size=p2.shape)\n",
    "        d = np.linalg.norm(q1 - q2)\n",
    "        return d < self.L\n",
    "    \n",
    "    def estimate_probability(self, p1, p2, sigma1, sigma2, N=100000):\n",
    "        '''\n",
    "        Estimate crosslink probability using Monte Carlo sampling.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        p1 : np.ndarray\n",
    "            Center position of first point (shape: (3,))\n",
    "        p2 : np.ndarray\n",
    "            Center position of second point (shape: (3,))\n",
    "        sigma1 : float\n",
    "            Positional uncertainty (radius) for first point\n",
    "        sigma2 : float\n",
    "            Positional uncertainty (radius) for second point\n",
    "        N : int\n",
    "            Number of Monte Carlo trials\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        float\n",
    "            Estimated probability of crosslinking (between 0 and 1)\n",
    "        '''\n",
    "        success_count = 0\n",
    "        for _ in range(N):\n",
    "            if self._pick_points(p1, p2, sigma1, sigma2):\n",
    "                success_count += 1\n",
    "        \n",
    "        return success_count / N\n",
    "    \n",
    "    def generate_configurations(self, num_configs, \n",
    "                               position_range=(-50, 50),\n",
    "                               sigma_range=(1, 15),\n",
    "                               N_trials=100000,\n",
    "                               verbose=True):\n",
    "        '''\n",
    "        Generate random configurations and compute crosslink probabilities.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        num_configs : int\n",
    "            Number of configurations to generate\n",
    "        position_range : tuple\n",
    "            Range for random point positions (min, max)\n",
    "        sigma_range : tuple\n",
    "            Range for random sigma values (min, max)\n",
    "        N_trials : int\n",
    "            Number of Monte Carlo trials per configuration\n",
    "        verbose : bool\n",
    "            Whether to print progress\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        None (stores results in self.configurations and self.results)\n",
    "        '''\n",
    "        self.configurations = []\n",
    "        self.results = []\n",
    "        \n",
    "        for i in range(num_configs):\n",
    "            # Generate random configuration\n",
    "            p1 = np.random.uniform(position_range[0], position_range[1], size=(3,))\n",
    "            p2 = np.random.uniform(position_range[0], position_range[1], size=(3,))\n",
    "            sigma1 = np.random.uniform(sigma_range[0], sigma_range[1])\n",
    "            sigma2 = np.random.uniform(sigma_range[0], sigma_range[1])\n",
    "            \n",
    "            # Compute distance between centers\n",
    "            d = np.linalg.norm(p1 - p2)\n",
    "            \n",
    "            # Estimate probability\n",
    "            prob = self.estimate_probability(p1, p2, sigma1, sigma2, N=N_trials)\n",
    "            \n",
    "            # Store configuration\n",
    "            config = {\n",
    "                'p1': p1,\n",
    "                'p2': p2,\n",
    "                'sigma1': sigma1,\n",
    "                'sigma2': sigma2,\n",
    "                'd': d,\n",
    "                'L': self.L,\n",
    "                'probability': prob\n",
    "            }\n",
    "            self.configurations.append(config)\n",
    "            \n",
    "            # Store result for training data (invariant features)\n",
    "            self.results.append([d, sigma1, sigma2, self.L, prob])\n",
    "            \n",
    "            if verbose and (i + 1) % max(1, num_configs // 10) == 0:\n",
    "                print(f\"Generated {i + 1}/{num_configs} configurations...\")\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Completed! Generated {num_configs} configurations.\")\n",
    "    \n",
    "    def save_training_data(self, filename='surrogate_model_data', format='npz'):\n",
    "        '''\n",
    "        Save generated training data to disk.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        filename : str\n",
    "            Base filename (without extension)\n",
    "        format : str\n",
    "            'npz' for NumPy compressed or 'hdf5' for HDF5 format\n",
    "        '''\n",
    "        if not self.results:\n",
    "            raise ValueError(\"No data to save. Run generate_configurations() first.\")\n",
    "        \n",
    "        results_array = np.array(self.results)\n",
    "        X_data = results_array[:, :-1]  # Features: [d, sigma1, sigma2, L]\n",
    "        y_data = results_array[:, -1:]  # Target: [probability]\n",
    "        \n",
    "        if format == 'npz':\n",
    "            np.savez_compressed(f'{filename}.npz', X=X_data, y=y_data)\n",
    "            print(f\"Saved training data to {filename}.npz\")\n",
    "        elif format == 'hdf5':\n",
    "            with h5py.File(f'{filename}.h5', 'w') as f:\n",
    "                f.create_dataset('X', data=X_data, compression='gzip')\n",
    "                f.create_dataset('y', data=y_data, compression='gzip')\n",
    "            print(f\"Saved training data to {filename}.h5\")\n",
    "        else:\n",
    "            raise ValueError(\"Format must be 'npz' or 'hdf5'\")\n",
    "    \n",
    "    def prepare_training_data(self, test_size=0.2, save_scaler=True):\n",
    "        '''\n",
    "        Prepare and normalize training data for neural network.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        test_size : float\n",
    "            Fraction of data to use for validation\n",
    "        save_scaler : bool\n",
    "            Whether to save the fitted scaler to disk\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        tuple\n",
    "            (X_train_scaled, X_val_scaled, y_train, y_val, scaler)\n",
    "        '''\n",
    "        if not self.results:\n",
    "            raise ValueError(\"No data to prepare. Run generate_configurations() first.\")\n",
    "        \n",
    "        results_array = np.array(self.results)\n",
    "        X_all = results_array[:, :-1]  # Features: [d, sigma1, sigma2, L]\n",
    "        y_all = results_array[:, -1:]  # Target: [probability]\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_all, y_all, test_size=test_size, random_state=42\n",
    "        )\n",
    "        \n",
    "        # Fit scaler on training data only\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_val_scaled = scaler.transform(X_val)\n",
    "        \n",
    "        if save_scaler:\n",
    "            with open('data_scaler.pkl', 'wb') as f:\n",
    "                pickle.dump(scaler, f)\n",
    "            print(\"Saved scaler to data_scaler.pkl\")\n",
    "        \n",
    "        print(f\"Training set: {X_train_scaled.shape[0]} samples\")\n",
    "        print(f\"Validation set: {X_val_scaled.shape[0]} samples\")\n",
    "        \n",
    "        return X_train_scaled, X_val_scaled, y_train, y_val, scaler\n",
    "    \n",
    "    def visualize_configurations(self, num_visualize=None, output_dir='output_figures'):\n",
    "        '''\n",
    "        Visualize generated configurations as 3D sphere plots.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        num_visualize : int or None\n",
    "            Number of configurations to visualize (None = visualize all)\n",
    "        output_dir : str\n",
    "            Directory to save PDF file\n",
    "        '''\n",
    "        if not self.configurations:\n",
    "            raise ValueError(\"No configurations to visualize. Run generate_configurations() first.\")\n",
    "        \n",
    "        # Create output directory if it doesn't exist\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Determine how many to visualize\n",
    "        if num_visualize is None:\n",
    "            num_visualize = len(self.configurations)\n",
    "        else:\n",
    "            num_visualize = min(num_visualize, len(self.configurations))\n",
    "        \n",
    "        pdf_path = os.path.join(output_dir, 'configurations_visualization.pdf')\n",
    "        \n",
    "        with PdfPages(pdf_path) as pdf:\n",
    "            for i in range(num_visualize):\n",
    "                config = self.configurations[i]\n",
    "                \n",
    "                fig = plt.figure(figsize=(12, 10))\n",
    "                ax = fig.add_subplot(111, projection='3d')\n",
    "                \n",
    "                p1 = config['p1']\n",
    "                p2 = config['p2']\n",
    "                sigma1 = config['sigma1']\n",
    "                sigma2 = config['sigma2']\n",
    "                d = config['d']\n",
    "                prob = config['probability']\n",
    "                \n",
    "                # Draw spheres\n",
    "                u = np.linspace(0, 2 * np.pi, 50)\n",
    "                v = np.linspace(0, np.pi, 50)\n",
    "                \n",
    "                # Sphere 1\n",
    "                x1 = p1[0] + sigma1 * np.outer(np.cos(u), np.sin(v))\n",
    "                y1 = p1[1] + sigma1 * np.outer(np.sin(u), np.sin(v))\n",
    "                z1 = p1[2] + sigma1 * np.outer(np.ones(np.size(u)), np.cos(v))\n",
    "                ax.plot_surface(x1, y1, z1, alpha=0.3, color='blue', label='Sphere 1')\n",
    "                \n",
    "                # Sphere 2\n",
    "                x2 = p2[0] + sigma2 * np.outer(np.cos(u), np.sin(v))\n",
    "                y2 = p2[1] + sigma2 * np.outer(np.sin(u), np.sin(v))\n",
    "                z2 = p2[2] + sigma2 * np.outer(np.ones(np.size(u)), np.cos(v))\n",
    "                ax.plot_surface(x2, y2, z2, alpha=0.3, color='red', label='Sphere 2')\n",
    "                \n",
    "                # Plot centers\n",
    "                ax.scatter(*p1, color='blue', s=100, marker='o', label='Center 1')\n",
    "                ax.scatter(*p2, color='red', s=100, marker='o', label='Center 2')\n",
    "                \n",
    "                # Draw line between centers\n",
    "                ax.plot([p1[0], p2[0]], [p1[1], p2[1]], [p1[2], p2[2]], \n",
    "                       'k--', linewidth=2, label=f'd = {d:.2f}Å')\n",
    "                \n",
    "                # Annotations\n",
    "                ax.text(p1[0], p1[1], p1[2] + sigma1 + 5, \n",
    "                       f'σ₁ = {sigma1:.2f}Å\\np₁ = ({p1[0]:.1f}, {p1[1]:.1f}, {p1[2]:.1f})',\n",
    "                       fontsize=9, ha='center')\n",
    "                ax.text(p2[0], p2[1], p2[2] + sigma2 + 5, \n",
    "                       f'σ₂ = {sigma2:.2f}Å\\np₂ = ({p2[0]:.1f}, {p2[1]:.1f}, {p2[2]:.1f})',\n",
    "                       fontsize=9, ha='center')\n",
    "                \n",
    "                # Set labels and title\n",
    "                ax.set_xlabel('X (Å)')\n",
    "                ax.set_ylabel('Y (Å)')\n",
    "                ax.set_zlabel('Z (Å)')\n",
    "                ax.set_title(f'Configuration {i + 1}\\n'\n",
    "                           f'Crosslinker Length L = {self.L:.1f}Å\\n'\n",
    "                           f'Distance d = {d:.2f}Å\\n'\n",
    "                           f'Crosslink Probability = {prob:.4f}',\n",
    "                           fontsize=12, fontweight='bold')\n",
    "                \n",
    "                ax.legend(loc='upper right')\n",
    "                \n",
    "                # Equal aspect ratio\n",
    "                max_range = np.array([\n",
    "                    max(abs(p1[0]) + sigma1, abs(p2[0]) + sigma2),\n",
    "                    max(abs(p1[1]) + sigma1, abs(p2[1]) + sigma2),\n",
    "                    max(abs(p1[2]) + sigma1, abs(p2[2]) + sigma2)\n",
    "                ]).max()\n",
    "                \n",
    "                mid_x = (p1[0] + p2[0]) / 2\n",
    "                mid_y = (p1[1] + p2[1]) / 2\n",
    "                mid_z = (p1[2] + p2[2]) / 2\n",
    "                \n",
    "                ax.set_xlim(mid_x - max_range * 0.6, mid_x + max_range * 0.6)\n",
    "                ax.set_ylim(mid_y - max_range * 0.6, mid_y + max_range * 0.6)\n",
    "                ax.set_zlim(mid_z - max_range * 0.6, mid_z + max_range * 0.6)\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                pdf.savefig(fig, bbox_inches='tight')\n",
    "                plt.close(fig)\n",
    "                \n",
    "                if (i + 1) % 10 == 0:\n",
    "                    print(f\"Visualized {i + 1}/{num_visualize} configurations...\")\n",
    "        \n",
    "        print(f\"Saved visualization to {pdf_path}\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Create estimator\n",
    "    estimator = CrosslinkProbabilityEstimator(L=21.0)\n",
    "    \n",
    "    # Generate configurations\n",
    "    estimator.generate_configurations(num_configs=100, N_trials=100000)\n",
    "    \n",
    "    # Save training data\n",
    "    estimator.save_training_data(filename='surrogate_model_data', format='hdf5')\n",
    "    \n",
    "    # Prepare for training\n",
    "    X_train, X_val, y_train, y_val, scaler = estimator.prepare_training_data()\n",
    "    \n",
    "    # Visualize first 20 configurations\n",
    "    estimator.visualize_configurations(num_visualize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6895defb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imptorch-latest-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
