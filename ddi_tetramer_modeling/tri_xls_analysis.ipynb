{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d08d81fd",
   "metadata": {},
   "source": [
    "***Analysis script for the trifunctional crosslinks of DDI1_DDI2 tetramer protein complex***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "012fa2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "import argparse\n",
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72d5475a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw trifunctional XL-MS data: \n",
      "    Protein1 Residue1 Protein2 Residue2 Protein3 Residue3\n",
      "0      DDI1       77     DDI1      161     DDI1      291\n",
      "1      DDI1       77     DDI1      291     DDI1      382\n",
      "2      DDI1      133     DDI1      133     DDI1      213\n",
      "3      DDI1      133     DDI1      133     DDI1      291\n",
      "4      DDI1      133     DDI1      161     DDI1      213\n",
      "5      DDI1      133     DDI1      161     DDI1      291\n",
      "6      DDI1      133     DDI1      161     DDI1      345\n",
      "7      DDI1      133     DDI1      161     DDI2      337\n",
      "8      DDI1      133     DDI1      213     DDI1      291\n",
      "9      DDI1      133     DDI1      213     DDI1      345\n",
      "10     DDI1      133     DDI1      213     DDI2      337\n",
      "11     DDI1      133     DDI1      291     DDI1      291\n",
      "12     DDI1      133     DDI1      291     DDI1      382\n",
      "13     DDI1      161     DDI1      161     DDI1      291\n",
      "14     DDI1      161     DDI1      213     DDI1      291\n",
      "15     DDI1      161     DDI1      291     DDI1      382\n",
      "16     DDI1      190     DDI1      291     DDI1      382\n",
      "17     DDI1       77     DDI1      213     DDI1      291\n",
      "18     DDI1      213     DDI1      291     DDI1      382\n",
      "19     DDI1      291     DDI1      291     DDI1      345\n",
      "20     DDI1      291     DDI1      291     DDI1      382\n",
      "non-redundant trifunctional XL-MS data: \n",
      "    Protein1 Residue1 Protein2 Residue2 Protein3 Residue3\n",
      "0      DDI1       77     DDI1      161     DDI1      291\n",
      "1      DDI1       77     DDI1      291     DDI1      382\n",
      "2      DDI1      133     DDI1      133     DDI1      213\n",
      "3      DDI1      133     DDI1      133     DDI1      291\n",
      "4      DDI1      133     DDI1      161     DDI1      213\n",
      "5      DDI1      133     DDI1      161     DDI1      291\n",
      "6      DDI1      133     DDI1      161     DDI1      345\n",
      "7      DDI1      133     DDI1      161     DDI2      337\n",
      "8      DDI1      133     DDI1      213     DDI1      291\n",
      "9      DDI1      133     DDI1      213     DDI1      345\n",
      "10     DDI1      133     DDI1      213     DDI2      337\n",
      "11     DDI1      133     DDI1      291     DDI1      291\n",
      "12     DDI1      133     DDI1      291     DDI1      382\n",
      "13     DDI1      161     DDI1      161     DDI1      291\n",
      "14     DDI1      161     DDI1      213     DDI1      291\n",
      "15     DDI1      161     DDI1      291     DDI1      382\n",
      "16     DDI1      190     DDI1      291     DDI1      382\n",
      "17     DDI1       77     DDI1      213     DDI1      291\n",
      "18     DDI1      213     DDI1      291     DDI1      382\n",
      "19     DDI1      291     DDI1      291     DDI1      345\n",
      "20     DDI1      291     DDI1      291     DDI1      382\n",
      "Residue 345 is a lysine in DDI1\n",
      "Residue 337 is a lysine in DDI2\n"
     ]
    }
   ],
   "source": [
    "# Read in the csv file for the trifunctional XL-MS data\n",
    "# path to current working directory \n",
    "dir_path = os.getcwd()\n",
    "xls_data_dir = os.path.join(dir_path, 'derived_data/xls/')\n",
    "fasta_data_dir = os.path.join(dir_path, 'data/fasta/')\n",
    "df = pd.read_csv(os.path.join(xls_data_dir, 'ddi_trifunctional.csv'))\n",
    "\n",
    "# Use some biopython module to read in fasta files for analysis later\n",
    "# Read in fasta files for DDI1 and DDI2\n",
    "ddi1_fasta = list(SeqIO.parse(os.path.join(fasta_data_dir, 'ddi1.fasta'), \"fasta\"))\n",
    "ddi2_fasta = list(SeqIO.parse(os.path.join(fasta_data_dir, 'ddi2.fasta'), \"fasta\"))\n",
    "\n",
    "# Remove the K from residue1/2/3 columns \n",
    "df['Residue1'] = df['Residue1'].str.replace('K', '')\n",
    "df['Residue2'] = df['Residue2'].str.replace('K', '')\n",
    "df['Residue3'] = df['Residue3'].str.replace('K', '')\n",
    "print(f\"raw trifunctional XL-MS data: \\n\", df)\n",
    "\n",
    "# Remove redundant rows, where the order of the residues in a row, as long as the protein \n",
    "# names are the same, does not matter\n",
    "df['residue_list'] = df[['Residue1', 'Residue2', 'Residue3']].values.tolist()\n",
    "df['residue_list'] = df['residue_list'].apply(lambda x: sorted(x))\n",
    "df['protein_list'] = df[['Protein1', 'Protein2', 'Protein3']].values.tolist()\n",
    "df['protein_list'] = df['protein_list'].apply(lambda x: sorted(x))\n",
    "df['unique_id'] = df['residue_list'].astype(str) + '_' + df['protein_list'].astype(str)\n",
    "df = df.drop_duplicates(subset=['unique_id'])\n",
    "df = df.drop(columns=['residue_list', 'protein_list', 'unique_id'])\n",
    "print(f\"non-redundant trifunctional XL-MS data: \\n\", df)\n",
    "\n",
    "# Function to check if residues are lysines in the given fasta record\n",
    "def check_lysines(fasta_record, residue_list):\n",
    "    sequence = str(fasta_record.seq)\n",
    "    lysine_positions = [m.start() + 1 for m in re.finditer('K', sequence)]  # +1 for 1-based indexing\n",
    "    for residue in residue_list:\n",
    "        if int(residue) not in lysine_positions:\n",
    "            print(f\"Warning: Residue {residue} is not a lysine in {fasta_record.id}\")\n",
    "        else:\n",
    "            print(f\"Residue {residue} is a lysine in {fasta_record.id}\")\n",
    "\n",
    "# Check residues in DDI1\n",
    "check_lysines(ddi1_fasta[0], [345])\n",
    "check_lysines(ddi2_fasta[0], [337]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b489b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain analysis completed for DDI1\n",
      "Found 3 domains: [(1, 79), (142, 291), (295, 371)]\n",
      "Results saved to: output_data/domain_analysis/ddi1.json\n",
      "Domain analysis completed for DDI2\n",
      "Found 3 domains: [(1, 78), (133, 364), (375, 398)]\n",
      "Results saved to: output_data/domain_analysis/ddi2.json\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from Bio import SeqIO\n",
    "from Bio.PDB import PDBParser, DSSP\n",
    "\n",
    "class DomainAnalyzer:\n",
    "    \"\"\"\n",
    "    A class to analyze protein domains using AlphaFold structure predictions\n",
    "    and DSSP secondary structure analysis.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dssp_bin=\"dssp\"):\n",
    "        \"\"\"\n",
    "        Initialize the DomainAnalyzer.\n",
    "        \n",
    "        Args:\n",
    "            dssp_bin (str): Path to DSSP binary executable\n",
    "        \"\"\"\n",
    "        self.dssp_bin = dssp_bin\n",
    "        self.output_dir = Path(\"output_data/domain_analysis\")\n",
    "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    def get_disorder_from_alphafold(self, pdb_file):\n",
    "        \"\"\"\n",
    "        Use B-factor pLDDT<70 as disorder indicator per CA atom.\n",
    "        \n",
    "        Args:\n",
    "            pdb_file (str): Path to PDB file\n",
    "            \n",
    "        Returns:\n",
    "            np.array: Boolean array indicating disorder for each residue\n",
    "        \"\"\"\n",
    "        disorder = []\n",
    "        with open(pdb_file, 'r') as f:\n",
    "            for line in f:\n",
    "                if line.startswith(\"ATOM\") and line[12:16].strip() == \"CA\":\n",
    "                    b_factor = float(line[60:66])\n",
    "                    disorder.append(b_factor < 70)\n",
    "        return np.array(disorder)\n",
    "    \n",
    "    def find_domains(self, disorder_pred):\n",
    "        \"\"\"\n",
    "        Call contiguous ordered runs â‰¥8 aa as domains, merge small gaps.\n",
    "        \n",
    "        Args:\n",
    "            disorder_pred (np.array): Boolean array of disorder predictions\n",
    "            \n",
    "        Returns:\n",
    "            list: List of domain tuples (start, end) in 1-based indexing\n",
    "        \"\"\"\n",
    "        domains = []\n",
    "        start = None\n",
    "        n = len(disorder_pred)\n",
    "        \n",
    "        for i in range(n):\n",
    "            if not disorder_pred[i] and start is None:\n",
    "                start = i\n",
    "            if (disorder_pred[i] or i == n-1) and start is not None:\n",
    "                if i - start >= 8:\n",
    "                    domains.append((start + 1, i))  # 1-based indexing\n",
    "                start = None\n",
    "        \n",
    "        # Merge domains separated by <5 aa\n",
    "        merged = []\n",
    "        for dom in domains:\n",
    "            if not merged:\n",
    "                merged.append(dom)\n",
    "            else:\n",
    "                prev = merged[-1]\n",
    "                if dom[0] - prev[1] < 5:\n",
    "                    merged[-1] = (prev[0], dom[1])\n",
    "                else:\n",
    "                    merged.append(dom)\n",
    "        \n",
    "        return merged\n",
    "    \n",
    "    def run_dssp_analysis(self, pdb_file):\n",
    "        \"\"\"\n",
    "        Run DSSP to extract secondary structure per residue.\n",
    "        \n",
    "        Args:\n",
    "            pdb_file (str): Path to PDB file\n",
    "            \n",
    "        Returns:\n",
    "            DSSP object containing secondary structure information\n",
    "        \"\"\"\n",
    "        parser = PDBParser(QUIET=True)\n",
    "        struct = parser.get_structure(\"protein\", pdb_file)\n",
    "        dssp = DSSP(struct[0], pdb_file, dssp=self.dssp_bin)\n",
    "        return dssp\n",
    "    \n",
    "    def extend_domains_with_ss(self, domains, pdb_file):\n",
    "        \"\"\"\n",
    "        Grow domain boundaries while adjacent residues are helix/strand.\n",
    "        \n",
    "        Args:\n",
    "            domains (list): List of domain tuples\n",
    "            pdb_file (str): Path to PDB file\n",
    "            \n",
    "        Returns:\n",
    "            list: List of extended domain tuples\n",
    "        \"\"\"\n",
    "        try:\n",
    "            dssp_data = self.run_dssp_analysis(pdb_file)\n",
    "            ss = [residue[2] for residue in dssp_data]\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: DSSP analysis failed for {pdb_file}: {e}\")\n",
    "            return domains\n",
    "        \n",
    "        extended = []\n",
    "        for start, end in domains:\n",
    "            i0, i1 = start - 1, end - 1  # Convert to 0-based\n",
    "            \n",
    "            # Extend start while previous residues are helix/strand\n",
    "            while i0 > 0 and ss[i0 - 1] in (\"H\", \"E\"):\n",
    "                i0 -= 1\n",
    "            \n",
    "            # Extend end while next residues are helix/strand\n",
    "            while i1 < len(ss) - 1 and ss[i1 + 1] in (\"H\", \"E\"):\n",
    "                i1 += 1\n",
    "            \n",
    "            extended.append((i0 + 1, i1 + 1))  # Convert back to 1-based\n",
    "        \n",
    "        return extended\n",
    "    \n",
    "    def get_protein_info(self, fasta_file):\n",
    "        \"\"\"\n",
    "        Extract protein information from FASTA file.\n",
    "        \n",
    "        Args:\n",
    "            fasta_file (str): Path to FASTA file\n",
    "            \n",
    "        Returns:\n",
    "            dict: Dictionary containing protein ID, description, and sequence length\n",
    "        \"\"\"\n",
    "        fasta_records = list(SeqIO.parse(fasta_file, \"fasta\"))\n",
    "        if not fasta_records:\n",
    "            raise ValueError(f\"No sequences found in {fasta_file}\")\n",
    "        \n",
    "        record = fasta_records[0]  # Take first sequence\n",
    "        return {\n",
    "            \"protein_id\": record.id,\n",
    "            \"description\": record.description,\n",
    "            \"sequence_length\": len(record.seq)\n",
    "        }\n",
    "    \n",
    "    def analyze_domains(self, fasta_file, pdb_file, output_name=None):\n",
    "        \"\"\"\n",
    "        Perform complete domain analysis and save results.\n",
    "        \n",
    "        Args:\n",
    "            fasta_file (str): Path to FASTA file\n",
    "            pdb_file (str): Path to PDB file\n",
    "            output_name (str, optional): Custom output filename (without extension)\n",
    "            \n",
    "        Returns:\n",
    "            dict: Domain analysis results\n",
    "        \"\"\"\n",
    "        # Get protein information\n",
    "        protein_info = self.get_protein_info(fasta_file)\n",
    "        \n",
    "        # Generate output filename if not provided\n",
    "        if output_name is None:\n",
    "            protein_id = protein_info[\"protein_id\"].replace(\"|\", \"_\")\n",
    "            output_name = f\"{protein_id}_domains\"\n",
    "        \n",
    "        # Perform domain analysis\n",
    "        disorder = self.get_disorder_from_alphafold(pdb_file)\n",
    "        initial_domains = self.find_domains(disorder)\n",
    "        extended_domains = self.extend_domains_with_ss(initial_domains, pdb_file)\n",
    "        \n",
    "        # Prepare results\n",
    "        results = {\n",
    "            \"protein_info\": protein_info,\n",
    "            \"analysis_parameters\": {\n",
    "                \"disorder_threshold\": 70,\n",
    "                \"minimum_domain_length\": 8,\n",
    "                \"merge_gap_threshold\": 5\n",
    "            },\n",
    "            \"input_files\": {\n",
    "                \"fasta_file\": str(fasta_file),\n",
    "                \"pdb_file\": str(pdb_file)\n",
    "            },\n",
    "            \"domain_analysis\": {\n",
    "                \"initial_domains\": initial_domains,\n",
    "                \"extended_domains\": extended_domains,\n",
    "                \"num_domains\": len(extended_domains),\n",
    "                \"total_domain_residues\": sum(end - start + 1 for start, end in extended_domains)\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Save to JSON file\n",
    "        output_file = self.output_dir / f\"{output_name}.json\"\n",
    "        with open(output_file, 'w') as f:\n",
    "            json.dump(results, f, indent=2)\n",
    "        \n",
    "        print(f\"Domain analysis completed for {protein_info['protein_id']}\")\n",
    "        print(f\"Found {len(extended_domains)} domains: {extended_domains}\")\n",
    "        print(f\"Results saved to: {output_file}\")\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Example usage function\n",
    "def analyze_ddi_proteins():\n",
    "    \"\"\"Example function to analyze DDI1 and DDI2 proteins.\"\"\"\n",
    " #   mkdssp_path = os.path.expanduser(\"~/.local/bin/mkdssp\")\n",
    " #   analyzer = DomainAnalyzer(dssp_bin=mkdssp_path)\n",
    "    analyzer = DomainAnalyzer()\n",
    "    \n",
    "    # Define file paths (adjust these to your actual file locations)\n",
    "    proteins = [\n",
    "        {\n",
    "            \"name\": \"DDI1\",\n",
    "            \"fasta\": \"data/fasta/ddi1.fasta\",\n",
    "            \"pdb\": \"data/pdb/ddi1.pdb\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"DDI2\", \n",
    "            \"fasta\": \"data/fasta/ddi2.fasta\",\n",
    "            \"pdb\": \"data/pdb/ddi2.pdb\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    results = {}\n",
    "    for protein in proteins:\n",
    "        if os.path.exists(protein[\"fasta\"]) and os.path.exists(protein[\"pdb\"]):\n",
    "            result = analyzer.analyze_domains(\n",
    "                protein[\"fasta\"], \n",
    "                protein[\"pdb\"], \n",
    "                protein[\"name\"].lower()\n",
    "            )\n",
    "            results[protein[\"name\"]] = result\n",
    "        else:\n",
    "            print(f\"Warning: Files not found for {protein['name']}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run analysis\n",
    "    results = analyze_ddi_proteins()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01746063",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imptorch-latest-cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
